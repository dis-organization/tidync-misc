---
title: "Tidy NetCDF examples"
author: "Michael D. Sumner"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    fig_width: 10
    fig_height: 10
vignette: >
  %\VignetteIndexEntry{Tidy NetCDF examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



Find an arbitrary NetCDF file. 

```{r}
f <- file.path("/rdsi/PUBLIC/raad", "data/ftp.ifremer.fr/ifremer/cersat/products/gridded/psi-concentration/data/antarctic/daily/netcdf/2013/20130415.nc")
```

NetCDF is a very widely use file format for storing array-based data as *variables*. The **variable's** space is defined by its **dimensions** and their metadata. Dimensions are by definition "one-dimensional" consisting of one or more elements, a rectilinear virtual array with coordinate metadata on its units, type and interpretation. The **space** of a variable is defined as one or more of the dimensions in the file, but a variable won't necessarily use all the available dimensions and no dimensions are mandatory or particularly special. 

Some conventions exist to define usage and minimal standards for metadata for particular file schemas, but these are
many, varied, and no particularly well adhered to in many contexts. 

A NetCDF file is essentially a container for simple array based data structures. There is limited capacity in the formal API for accessing data randomly within a variable, the primary mechanism is to define offset and stride (start and count) hyperslab indexes. (I.e. it's not possible to query a file for an arbitrary sparse set of values, without constructing a degenerate hyperslab query for each point or reading a hyperslab containing cells not in the set.)


## tidync

Tidync provides facilities to explore the contents of a NetCDF file and construct efficient queries to extract
arbitrary hyperslabs. These can be used directly in array contexts, or in "long form" database contexts. 

On first contact with the file, the available variables are reported (the first is made "active") and
the dimensions of the active variable are described.  The "active" variable may be specified with the `activate` function. 


```{r}
library(tidync)
tidync(f)

## activate another variable
tidync(f) %>% activate(concentration)
```

The term "hyperslab" is sometimes used to mean an arbitrarily-dimensioned array, and tidync uses this pattern for its main functions. 

The 'hyper_filter' function allows specification of expressions to subset a variable based on each dimension's coordinate values. 

If no expressions are included we are presented with a table containing a row for each dimension, its extent
in coordinates and its length. For convenience we also assign the activate form to an R variable, though we could
just chain the entire operation without this. 

```{r}
concentration <- tidync(f) %>% activate(concentration) 

concentration %>% hyper_filter() 
```




By specifying inequality expressions we see an *implicit* subsetting of the array. Everything so far is implicit to 
delay any file-based computation required to actually interact with the file and read from it. 

Notice that these are "name = expr" paired expressions, because the right hand side may be quite general we 
need the left hand side name to be assured of the name of the dimension referred to. 

```{r}

concentration %>% hyper_filter(nj = nj < 20)


```

We can also use the special internal variable 'step', which will test against position in the dimension elements '1:length' rather than the values. It's not different in this case because ni and nj are just position dimensions anyway. The special 'dplyr' adverbs like 'between' will work. 

```{r}
concentration %>% hyper_filter(ni = index < 20, nj = dplyr::between(index, 30, 100))

```

## Data extraction

How to use these idioms to extract actual data? 

We can now exercise these variable choice and dimension filters to return actual data, either in by slicing out a  "slab" in array-form, or as a data frame. 

```{r}
hf <- concentration %>% hyper_filter(ni = step < 20, nj = dplyr::between(step, 30, 100))

## as an array
arr <- hf %>% hyper_slice()
str(arr)

## as a data frame

#concentration %>% hyper_tibble() %>% filter(!is.na(concentration))

```


## real world example  - ROMS ocean model data

A ROMS file typically has many variables of large size. The geographic space is curvilinear, and so we can't use the usual affine tricks available to us with "rasters". But, ggplot2 has no problem taking our cell values with their multidimensional coordinate values, and plotting a raster from them in the grid space. 


```{r}
romsfile <- file.path("/rdsi/PRIVATE/raad","data_local/acecrc.org.au/ROMS/s_corney/cpolar/ocean_his_3307.nc")
format(file.info(romsfile)$size, sci = TRUE)
## this is a big file
tidync(romsfile)

tidync(romsfile) %>% activate(temp)
tidync(romsfile) %>% hyper_filter()

(tab <- tidync(romsfile) %>% activate(temp) %>% 
  hyper_tibble(xi_rho = step > 1000, s_rho = s_rho > -0.5, ocean_time = step == 1))

library(ggplot2)
ggplot(tab, aes(xi_rho, eta_rho, fill = temp)) + geom_raster() + facet_wrap(~s_rho)

```

Now for a different orientation, this time with only one longitude slice. This example really needs to map on the actual geographic depth here, so it will need to be points or a mesh, or perform resampling on a grid. 

```{r}
(tab <- tidync(romsfile) %>% activate(temp) %>% 
  hyper_tibble(xi_rho = step == 1200,  ocean_time = step < 12))

library(ggplot2)
## model grid Y and model grid Z
ggplot(tab, aes(eta_rho, s_rho, fill = temp)) + geom_raster() + facet_wrap(~ocean_time)
```
TBD: need some more real example data set. we can use these extractions for very efficient and flexible ways to build other objects. The tibble is fairly obviously directly ready for use in `ggplot2`, and with a little more work we could generate `raster` bricks.  A major motivation for this work is to be able to extract data *flexibly*, and so not be bound by the geographic assumptions of the raster package - tidync can define and pull out any arbitrary slab from any NetCDF variable, no matter it's dimensions or purpose.  Initial experiments show that for many-slice extractions (10s or 100s) the tidync approach will also be faster than the current raster implementation. 

